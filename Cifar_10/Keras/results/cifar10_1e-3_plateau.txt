# Training parameters
LEARNING_RATE = 1e-3
DATA_AUGMENTATION = True
BATCH_SIZE = 128
EPOCHS = 200
BATCH_NORMALIZATION = True
REGULARIZATION = 0.0
KERNEL_INITIALIZER = 'he_normal'
es = keras.callbacks.EarlyStopping(monitor='val_acc', patience=15)
reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=10, verbose=1)




Using TensorFlow backend.
Using data augmentation.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 32, 32, 3)         0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 32, 32, 32)        896
_________________________________________________________________
block1_bn1 (BatchNormalizati (None, 32, 32, 32)        128
_________________________________________________________________
block1_relu1 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 32, 32, 32)        9248
_________________________________________________________________
block1_bn2 (BatchNormalizati (None, 32, 32, 32)        128
_________________________________________________________________
block1_relu2 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
block1_maxpool (MaxPooling2D (None, 16, 16, 32)        0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 16, 16, 64)        18496
_________________________________________________________________
block2_bn1 (BatchNormalizati (None, 16, 16, 64)        256
_________________________________________________________________
block2_relu1 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 16, 16, 64)        36928
_________________________________________________________________
block2_bn2 (BatchNormalizati (None, 16, 16, 64)        256
_________________________________________________________________
block2_relu2 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
block2_maxpool (MaxPooling2D (None, 8, 8, 64)          0
_________________________________________________________________
flatten_1 (Flatten)          (None, 4096)              0
_________________________________________________________________
dense_1 (Dense)              (None, 512)               2097664
_________________________________________________________________
dense_bn1 (BatchNormalizatio (None, 512)               2048
_________________________________________________________________
dense_relu1 (Activation)     (None, 512)               0
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130
=================================================================
Total params: 2,171,178
Trainable params: 2,169,770
Non-trainable params: 1,408
_________________________________________________________________
Epoch 1/200
391/391 [==============================] - 16s 40ms/step - loss: 1.6553 - acc: 0.4209 - val_loss: 1.2998 - val_acc: 0.5258
Epoch 2/200
391/391 [==============================] - 14s 36ms/step - loss: 1.2655 - acc: 0.5452 - val_loss: 1.0377 - val_acc: 0.6254
Epoch 3/200
391/391 [==============================] - 14s 36ms/step - loss: 1.1050 - acc: 0.6048 - val_loss: 1.0241 - val_acc: 0.6419
Epoch 4/200
391/391 [==============================] - 14s 36ms/step - loss: 1.0074 - acc: 0.6439 - val_loss: 0.8395 - val_acc: 0.6972
Epoch 5/200
391/391 [==============================] - 14s 36ms/step - loss: 0.9416 - acc: 0.6658 - val_loss: 0.9342 - val_acc: 0.6720
Epoch 6/200
391/391 [==============================] - 14s 36ms/step - loss: 0.8971 - acc: 0.6853 - val_loss: 0.9163 - val_acc: 0.6902
Epoch 7/200
391/391 [==============================] - 14s 36ms/step - loss: 0.8622 - acc: 0.6975 - val_loss: 0.8669 - val_acc: 0.7029
Epoch 8/200
391/391 [==============================] - 14s 36ms/step - loss: 0.8181 - acc: 0.7126 - val_loss: 0.8414 - val_acc: 0.7129
Epoch 9/200
391/391 [==============================] - 14s 36ms/step - loss: 0.7912 - acc: 0.7229 - val_loss: 0.8718 - val_acc: 0.7062
Epoch 10/200
391/391 [==============================] - 14s 36ms/step - loss: 0.7651 - acc: 0.7346 - val_loss: 0.8004 - val_acc: 0.7251
Epoch 11/200
391/391 [==============================] - 14s 36ms/step - loss: 0.7475 - acc: 0.7400 - val_loss: 0.7789 - val_acc: 0.7336
Epoch 12/200
391/391 [==============================] - 14s 36ms/step - loss: 0.7216 - acc: 0.7466 - val_loss: 0.6284 - val_acc: 0.7805
Epoch 13/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6997 - acc: 0.7547 - val_loss: 0.6057 - val_acc: 0.7880
Epoch 14/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6904 - acc: 0.7580 - val_loss: 0.6710 - val_acc: 0.7666
Epoch 15/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6686 - acc: 0.7658 - val_loss: 0.6781 - val_acc: 0.7714
Epoch 16/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6590 - acc: 0.7678 - val_loss: 0.6245 - val_acc: 0.7887
Epoch 17/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6426 - acc: 0.7762 - val_loss: 0.8703 - val_acc: 0.7210
Epoch 18/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6297 - acc: 0.7810 - val_loss: 0.6360 - val_acc: 0.7808
Epoch 19/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6262 - acc: 0.7812 - val_loss: 0.5896 - val_acc: 0.7966
Epoch 20/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6083 - acc: 0.7879 - val_loss: 0.7741 - val_acc: 0.7468
Epoch 21/200
391/391 [==============================] - 14s 36ms/step - loss: 0.6026 - acc: 0.7894 - val_loss: 0.6105 - val_acc: 0.7974
Epoch 22/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5928 - acc: 0.7928 - val_loss: 0.7733 - val_acc: 0.7513
Epoch 23/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5820 - acc: 0.7975 - val_loss: 0.6821 - val_acc: 0.7780
Epoch 24/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5692 - acc: 0.8038 - val_loss: 0.6076 - val_acc: 0.7979
Epoch 25/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5693 - acc: 0.8021 - val_loss: 0.5423 - val_acc: 0.8164
Epoch 26/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5569 - acc: 0.8068 - val_loss: 0.5741 - val_acc: 0.8055
Epoch 27/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5580 - acc: 0.8062 - val_loss: 0.5898 - val_acc: 0.8003
Epoch 28/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5462 - acc: 0.8113 - val_loss: 0.7132 - val_acc: 0.7787
Epoch 29/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5450 - acc: 0.8133 - val_loss: 0.5194 - val_acc: 0.8217
Epoch 30/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5321 - acc: 0.8132 - val_loss: 0.6758 - val_acc: 0.7806
Epoch 31/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5221 - acc: 0.8194 - val_loss: 0.5122 - val_acc: 0.8223
Epoch 32/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5264 - acc: 0.8179 - val_loss: 0.6737 - val_acc: 0.7830
Epoch 33/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5187 - acc: 0.8200 - val_loss: 0.5506 - val_acc: 0.8116
Epoch 34/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5109 - acc: 0.8237 - val_loss: 0.5838 - val_acc: 0.8099
Epoch 35/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5091 - acc: 0.8219 - val_loss: 0.5065 - val_acc: 0.8246
Epoch 36/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5032 - acc: 0.8222 - val_loss: 0.5527 - val_acc: 0.8158
Epoch 37/200
391/391 [==============================] - 14s 36ms/step - loss: 0.5023 - acc: 0.8254 - val_loss: 0.5419 - val_acc: 0.8157
Epoch 38/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4994 - acc: 0.8250 - val_loss: 0.5785 - val_acc: 0.8132
Epoch 39/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4951 - acc: 0.8299 - val_loss: 0.5583 - val_acc: 0.8160
Epoch 40/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4838 - acc: 0.8307 - val_loss: 0.4926 - val_acc: 0.8380
Epoch 41/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4823 - acc: 0.8334 - val_loss: 0.5140 - val_acc: 0.8286
Epoch 42/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4789 - acc: 0.8338 - val_loss: 0.5800 - val_acc: 0.8109
Epoch 43/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4779 - acc: 0.8335 - val_loss: 0.5982 - val_acc: 0.8064
Epoch 44/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4761 - acc: 0.8355 - val_loss: 0.4878 - val_acc: 0.8380
Epoch 45/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4720 - acc: 0.8351 - val_loss: 0.5851 - val_acc: 0.8127
Epoch 46/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4692 - acc: 0.8372 - val_loss: 0.5208 - val_acc: 0.8301
Epoch 47/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4575 - acc: 0.8425 - val_loss: 0.5684 - val_acc: 0.8149
Epoch 48/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4645 - acc: 0.8375 - val_loss: 0.5566 - val_acc: 0.8212
Epoch 49/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4587 - acc: 0.8400 - val_loss: 0.5419 - val_acc: 0.8269
Epoch 50/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4573 - acc: 0.8420 - val_loss: 0.5340 - val_acc: 0.8279

Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 51/200
391/391 [==============================] - 14s 35ms/step - loss: 0.4249 - acc: 0.8522 - val_loss: 0.4335 - val_acc: 0.8545
Epoch 52/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4111 - acc: 0.8576 - val_loss: 0.4562 - val_acc: 0.8469
Epoch 53/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4134 - acc: 0.8566 - val_loss: 0.4238 - val_acc: 0.8548
Epoch 54/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4027 - acc: 0.8614 - val_loss: 0.4255 - val_acc: 0.8563
Epoch 55/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4040 - acc: 0.8593 - val_loss: 0.4470 - val_acc: 0.8506
Epoch 56/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4008 - acc: 0.8603 - val_loss: 0.4294 - val_acc: 0.8556
Epoch 57/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3981 - acc: 0.8618 - val_loss: 0.4174 - val_acc: 0.8593
Epoch 58/200
391/391 [==============================] - 14s 36ms/step - loss: 0.4008 - acc: 0.8623 - val_loss: 0.4296 - val_acc: 0.8548
Epoch 59/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3953 - acc: 0.8622 - val_loss: 0.4214 - val_acc: 0.8604
Epoch 60/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3961 - acc: 0.8625 - val_loss: 0.4315 - val_acc: 0.8560
Epoch 61/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3921 - acc: 0.8661 - val_loss: 0.4273 - val_acc: 0.8586
Epoch 62/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3866 - acc: 0.8646 - val_loss: 0.4444 - val_acc: 0.8534
Epoch 63/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3900 - acc: 0.8656 - val_loss: 0.4293 - val_acc: 0.8568
Epoch 64/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3866 - acc: 0.8643 - val_loss: 0.4282 - val_acc: 0.8578
Epoch 65/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3876 - acc: 0.8644 - val_loss: 0.4169 - val_acc: 0.8633
Epoch 66/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3859 - acc: 0.8670 - val_loss: 0.4488 - val_acc: 0.8508
Epoch 67/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3832 - acc: 0.8654 - val_loss: 0.4339 - val_acc: 0.8574
Epoch 68/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3845 - acc: 0.8657 - val_loss: 0.4274 - val_acc: 0.8576
Epoch 69/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3849 - acc: 0.8656 - val_loss: 0.4291 - val_acc: 0.8576
Epoch 70/200
391/391 [==============================] - 14s 35ms/step - loss: 0.3789 - acc: 0.8686 - val_loss: 0.4449 - val_acc: 0.8535
Epoch 71/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3806 - acc: 0.8670 - val_loss: 0.4272 - val_acc: 0.8582
Epoch 72/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3801 - acc: 0.8668 - val_loss: 0.4323 - val_acc: 0.8554
Epoch 73/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3746 - acc: 0.8695 - val_loss: 0.4353 - val_acc: 0.8574
Epoch 74/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3846 - acc: 0.8673 - val_loss: 0.4171 - val_acc: 0.8608
Epoch 75/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3783 - acc: 0.8689 - val_loss: 0.4375 - val_acc: 0.8544

Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 76/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3759 - acc: 0.8696 - val_loss: 0.4213 - val_acc: 0.8597
Epoch 77/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3717 - acc: 0.8707 - val_loss: 0.4250 - val_acc: 0.8576
Epoch 78/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3733 - acc: 0.8711 - val_loss: 0.4258 - val_acc: 0.8574
Epoch 79/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3737 - acc: 0.8691 - val_loss: 0.4259 - val_acc: 0.8575
Epoch 80/200
391/391 [==============================] - 14s 36ms/step - loss: 0.3696 - acc: 0.8703 - val_loss: 0.4239 - val_acc: 0.8582