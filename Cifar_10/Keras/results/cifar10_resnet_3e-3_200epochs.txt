# Training parameters
LEARNING_RATE = 3e-3
DATA_AUGMENTATION = True 
REGULARIZATION = 0.0
BATCH_SIZE = 128
EPOCHS = 200


Using TensorFlow backend.
Using data augmentation.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 32, 32, 16)   448         input_1[0][0]
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 32, 32, 16)   64          conv1[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           conv1_bn[0][0]
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_1[0][0]
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2a_branch2a[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           bn2a_branch2a[0][0]
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_2[0][0]
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2a_branch2b[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           bn2a_branch2b[0][0]
                                                                 activation_1[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_3[0][0]
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2b_branch2a[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           bn2b_branch2a[0][0]
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_4[0][0]
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2b_branch2b[0][0]
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           bn2b_branch2b[0][0]
                                                                 activation_3[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]
__________________________________________________________________________________________________
res2c_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_5[0][0]
__________________________________________________________________________________________________
bn2c_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2c_branch2a[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           bn2c_branch2a[0][0]
__________________________________________________________________________________________________
res2c_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_6[0][0]
__________________________________________________________________________________________________
bn2c_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2c_branch2b[0][0]
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           bn2c_branch2b[0][0]
                                                                 activation_5[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 16, 16, 32)   4640        activation_7[0][0]
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3a_branch2a[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           bn3a_branch2a[0][0]
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_8[0][0]
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 16, 16, 32)   544         activation_7[0][0]
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3a_branch2b[0][0]
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 16, 16, 32)   128         res3a_branch1[0][0]
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           bn3a_branch2b[0][0]
                                                                 bn3a_branch1[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 16, 16, 32)   9248        activation_9[0][0]
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3b_branch2a[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           bn3b_branch2a[0][0]
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_10[0][0]
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3b_branch2b[0][0]
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           bn3b_branch2b[0][0]
                                                                 activation_9[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]
__________________________________________________________________________________________________
res3c_branch2a (Conv2D)         (None, 16, 16, 32)   9248        activation_11[0][0]
__________________________________________________________________________________________________
bn3c_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3c_branch2a[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           bn3c_branch2a[0][0]
__________________________________________________________________________________________________
res3c_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_12[0][0]
__________________________________________________________________________________________________
bn3c_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3c_branch2b[0][0]
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           bn3c_branch2b[0][0]
                                                                 activation_11[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 8, 8, 64)     18496       activation_13[0][0]
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4a_branch2a[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           bn4a_branch2a[0][0]
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_14[0][0]
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 8, 8, 64)     2112        activation_13[0][0]
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4a_branch2b[0][0]
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 8, 8, 64)     256         res4a_branch1[0][0]
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           bn4a_branch2b[0][0]
                                                                 bn4a_branch1[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 8, 8, 64)     36928       activation_15[0][0]
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4b_branch2a[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           bn4b_branch2a[0][0]
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_16[0][0]
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4b_branch2b[0][0]
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           bn4b_branch2b[0][0]
                                                                 activation_15[0][0]
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]
__________________________________________________________________________________________________
res4c_branch2a (Conv2D)         (None, 8, 8, 64)     36928       activation_17[0][0]
__________________________________________________________________________________________________
bn4c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4c_branch2a[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           bn4c_branch2a[0][0]
__________________________________________________________________________________________________
res4c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_18[0][0]
__________________________________________________________________________________________________
bn4c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4c_branch2b[0][0]
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           bn4c_branch2b[0][0]
                                                                 activation_17[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]
__________________________________________________________________________________________________
avg_pool (AveragePooling2D)     (None, 4, 4, 64)     0           activation_19[0][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1024)         0           avg_pool[0][0]
__________________________________________________________________________________________________
fc (Dense)                      (None, 10)           10250       flatten_1[0][0]
==================================================================================================
Total params: 284,426
Trainable params: 282,858
Non-trainable params: 1,568
__________________________________________________________________________________________________
Epoch 1/200
391/391 [==============================] - 25s 65ms/step - loss: 1.9360 - acc: 0.3320 - val_loss: 1.6418 - val_acc: 0.4323
Epoch 2/200
391/391 [==============================] - 22s 56ms/step - loss: 1.4923 - acc: 0.4660 - val_loss: 1.4808 - val_acc: 0.4910
Epoch 3/200
391/391 [==============================] - 22s 56ms/step - loss: 1.2603 - acc: 0.5511 - val_loss: 1.8620 - val_acc: 0.4669
Epoch 4/200
391/391 [==============================] - 22s 56ms/step - loss: 1.0903 - acc: 0.6132 - val_loss: 1.3610 - val_acc: 0.5859
Epoch 5/200
391/391 [==============================] - 22s 56ms/step - loss: 0.9425 - acc: 0.6690 - val_loss: 0.9497 - val_acc: 0.6800
Epoch 6/200
391/391 [==============================] - 22s 56ms/step - loss: 0.8539 - acc: 0.6992 - val_loss: 0.8602 - val_acc: 0.7099
Epoch 7/200
391/391 [==============================] - 22s 56ms/step - loss: 0.7817 - acc: 0.7285 - val_loss: 0.9413 - val_acc: 0.6845
Epoch 8/200
391/391 [==============================] - 22s 56ms/step - loss: 0.7259 - acc: 0.7450 - val_loss: 0.9660 - val_acc: 0.6887
Epoch 9/200
391/391 [==============================] - 22s 56ms/step - loss: 0.6782 - acc: 0.7631 - val_loss: 0.7206 - val_acc: 0.7607
Epoch 10/200
391/391 [==============================] - 22s 56ms/step - loss: 0.6410 - acc: 0.7783 - val_loss: 0.8944 - val_acc: 0.7172
Epoch 11/200
391/391 [==============================] - 22s 56ms/step - loss: 0.6118 - acc: 0.7880 - val_loss: 0.9467 - val_acc: 0.7170
Epoch 12/200
391/391 [==============================] - 22s 57ms/step - loss: 0.5842 - acc: 0.7969 - val_loss: 0.7065 - val_acc: 0.7717
Epoch 13/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5610 - acc: 0.8061 - val_loss: 0.6777 - val_acc: 0.7796
Epoch 14/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5378 - acc: 0.8157 - val_loss: 0.7403 - val_acc: 0.7692
Epoch 15/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5185 - acc: 0.8203 - val_loss: 0.6530 - val_acc: 0.7857
Epoch 16/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5002 - acc: 0.8260 - val_loss: 0.8683 - val_acc: 0.7501
Epoch 17/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4810 - acc: 0.8325 - val_loss: 0.6399 - val_acc: 0.7934
Epoch 18/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4766 - acc: 0.8332 - val_loss: 0.5866 - val_acc: 0.8084
Epoch 19/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4587 - acc: 0.8415 - val_loss: 0.4954 - val_acc: 0.8294
Epoch 20/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4447 - acc: 0.8444 - val_loss: 0.8046 - val_acc: 0.7580
Epoch 21/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4372 - acc: 0.8484 - val_loss: 0.6055 - val_acc: 0.8099
Epoch 22/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4236 - acc: 0.8525 - val_loss: 0.6040 - val_acc: 0.8108
Epoch 23/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4196 - acc: 0.8534 - val_loss: 0.5058 - val_acc: 0.8354
Epoch 24/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4080 - acc: 0.8582 - val_loss: 0.4980 - val_acc: 0.8421
Epoch 25/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4050 - acc: 0.8578 - val_loss: 0.5964 - val_acc: 0.8070
Epoch 26/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3935 - acc: 0.8623 - val_loss: 0.5482 - val_acc: 0.8270
Epoch 27/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3817 - acc: 0.8679 - val_loss: 0.8638 - val_acc: 0.7606
Epoch 28/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3743 - acc: 0.8679 - val_loss: 0.6410 - val_acc: 0.8057
Epoch 29/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3675 - acc: 0.8719 - val_loss: 0.6030 - val_acc: 0.8122
Epoch 30/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3639 - acc: 0.8731 - val_loss: 0.6284 - val_acc: 0.8074
Epoch 31/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3550 - acc: 0.8762 - val_loss: 0.6122 - val_acc: 0.8105
Epoch 32/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3458 - acc: 0.8804 - val_loss: 0.5134 - val_acc: 0.8401
Epoch 33/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3401 - acc: 0.8822 - val_loss: 0.5178 - val_acc: 0.8369
Epoch 34/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3374 - acc: 0.8820 - val_loss: 0.4975 - val_acc: 0.8421
Epoch 35/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3298 - acc: 0.8843 - val_loss: 0.5661 - val_acc: 0.8345
Epoch 36/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3280 - acc: 0.8864 - val_loss: 0.5489 - val_acc: 0.8338
Epoch 37/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3230 - acc: 0.8866 - val_loss: 0.6203 - val_acc: 0.8251
Epoch 38/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3208 - acc: 0.8897 - val_loss: 0.4286 - val_acc: 0.8608
Epoch 39/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3163 - acc: 0.8910 - val_loss: 0.5174 - val_acc: 0.8410
Epoch 40/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3109 - acc: 0.8923 - val_loss: 0.5284 - val_acc: 0.8394
Epoch 41/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3051 - acc: 0.8937 - val_loss: 0.6499 - val_acc: 0.8163
Epoch 42/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3027 - acc: 0.8942 - val_loss: 0.4850 - val_acc: 0.8442
Epoch 43/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2957 - acc: 0.8961 - val_loss: 0.4894 - val_acc: 0.8512
Epoch 44/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2970 - acc: 0.8964 - val_loss: 0.4934 - val_acc: 0.8432
Epoch 45/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2863 - acc: 0.9005 - val_loss: 0.5575 - val_acc: 0.8393
Epoch 46/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2897 - acc: 0.8968 - val_loss: 0.5196 - val_acc: 0.8435
Epoch 47/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2842 - acc: 0.8992 - val_loss: 0.5916 - val_acc: 0.8222
Epoch 48/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2795 - acc: 0.9009 - val_loss: 0.6057 - val_acc: 0.8295
Epoch 49/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2785 - acc: 0.9018 - val_loss: 0.5057 - val_acc: 0.8532
Epoch 50/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2757 - acc: 0.9025 - val_loss: 0.5399 - val_acc: 0.8432
Epoch 51/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2668 - acc: 0.9062 - val_loss: 0.4676 - val_acc: 0.8629
Epoch 52/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2701 - acc: 0.9058 - val_loss: 0.3896 - val_acc: 0.8775
Epoch 53/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2582 - acc: 0.9096 - val_loss: 0.4874 - val_acc: 0.8576
Epoch 54/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2582 - acc: 0.9098 - val_loss: 0.5965 - val_acc: 0.8396
Epoch 55/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2570 - acc: 0.9089 - val_loss: 0.4727 - val_acc: 0.8648
Epoch 56/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2580 - acc: 0.9100 - val_loss: 0.5366 - val_acc: 0.8536
Epoch 57/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2494 - acc: 0.9120 - val_loss: 0.4922 - val_acc: 0.8479
Epoch 58/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2515 - acc: 0.9119 - val_loss: 0.4926 - val_acc: 0.8561
Epoch 59/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2471 - acc: 0.9131 - val_loss: 0.6063 - val_acc: 0.8279
Epoch 60/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2473 - acc: 0.9136 - val_loss: 0.5618 - val_acc: 0.8416
Epoch 61/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2449 - acc: 0.9128 - val_loss: 0.5230 - val_acc: 0.8482
Epoch 62/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2415 - acc: 0.9146 - val_loss: 0.5004 - val_acc: 0.8596
Epoch 63/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2441 - acc: 0.9150 - val_loss: 0.4607 - val_acc: 0.8635
Epoch 64/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2382 - acc: 0.9154 - val_loss: 0.5771 - val_acc: 0.8459
Epoch 65/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2376 - acc: 0.9162 - val_loss: 0.5109 - val_acc: 0.8551
Epoch 66/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2332 - acc: 0.9175 - val_loss: 0.4532 - val_acc: 0.8680
Epoch 67/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2272 - acc: 0.9199 - val_loss: 0.4994 - val_acc: 0.8609
Epoch 68/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2327 - acc: 0.9189 - val_loss: 0.3686 - val_acc: 0.8841
Epoch 69/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2264 - acc: 0.9199 - val_loss: 0.4345 - val_acc: 0.8694
Epoch 70/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2278 - acc: 0.9210 - val_loss: 0.5510 - val_acc: 0.8476
Epoch 71/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2230 - acc: 0.9222 - val_loss: 0.4459 - val_acc: 0.8714
Epoch 72/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2220 - acc: 0.9219 - val_loss: 0.3898 - val_acc: 0.8805
Epoch 73/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2186 - acc: 0.9220 - val_loss: 0.6824 - val_acc: 0.8286
Epoch 74/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2218 - acc: 0.9223 - val_loss: 0.4293 - val_acc: 0.8786
Epoch 75/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2176 - acc: 0.9238 - val_loss: 0.4862 - val_acc: 0.8616
Epoch 76/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2198 - acc: 0.9231 - val_loss: 0.5230 - val_acc: 0.8598
Epoch 77/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2117 - acc: 0.9251 - val_loss: 0.5158 - val_acc: 0.8603
Epoch 78/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2151 - acc: 0.9240 - val_loss: 0.5210 - val_acc: 0.8596
Epoch 79/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2083 - acc: 0.9275 - val_loss: 0.4478 - val_acc: 0.8732
Epoch 80/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2138 - acc: 0.9242 - val_loss: 0.4721 - val_acc: 0.8663
Epoch 81/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2050 - acc: 0.9281 - val_loss: 0.3814 - val_acc: 0.8882
Epoch 82/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2079 - acc: 0.9271 - val_loss: 0.5106 - val_acc: 0.8573
Epoch 83/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2071 - acc: 0.9269 - val_loss: 0.4613 - val_acc: 0.8699
Epoch 84/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2050 - acc: 0.9281 - val_loss: 0.4808 - val_acc: 0.8614
Epoch 85/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2047 - acc: 0.9277 - val_loss: 0.4746 - val_acc: 0.8686
Epoch 86/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1949 - acc: 0.9314 - val_loss: 0.5040 - val_acc: 0.8674
Epoch 87/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1966 - acc: 0.9308 - val_loss: 0.4419 - val_acc: 0.8744
Epoch 88/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1976 - acc: 0.9300 - val_loss: 0.5720 - val_acc: 0.8517
Epoch 89/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1996 - acc: 0.9295 - val_loss: 0.4302 - val_acc: 0.8774
Epoch 90/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1879 - acc: 0.9326 - val_loss: 0.5139 - val_acc: 0.8652
Epoch 91/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1933 - acc: 0.9318 - val_loss: 0.4696 - val_acc: 0.8766
Epoch 92/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1995 - acc: 0.9283 - val_loss: 0.5395 - val_acc: 0.8575
Epoch 93/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1893 - acc: 0.9323 - val_loss: 0.4680 - val_acc: 0.8745
Epoch 94/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1903 - acc: 0.9324 - val_loss: 0.5393 - val_acc: 0.8621
Epoch 95/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1899 - acc: 0.9335 - val_loss: 0.4883 - val_acc: 0.8679
Epoch 96/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1864 - acc: 0.9343 - val_loss: 0.4617 - val_acc: 0.8719
Epoch 97/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1853 - acc: 0.9348 - val_loss: 0.5651 - val_acc: 0.8484
Epoch 98/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1862 - acc: 0.9340 - val_loss: 0.4316 - val_acc: 0.8773
Epoch 99/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1832 - acc: 0.9354 - val_loss: 0.4158 - val_acc: 0.8857
Epoch 100/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1826 - acc: 0.9351 - val_loss: 0.4172 - val_acc: 0.8825
Epoch 101/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1826 - acc: 0.9344 - val_loss: 0.5288 - val_acc: 0.8621
Epoch 102/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1793 - acc: 0.9356 - val_loss: 0.5209 - val_acc: 0.8658
Epoch 103/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1820 - acc: 0.9356 - val_loss: 0.5513 - val_acc: 0.8525
Epoch 104/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1795 - acc: 0.9362 - val_loss: 0.6232 - val_acc: 0.8507
Epoch 105/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1758 - acc: 0.9379 - val_loss: 0.4332 - val_acc: 0.8819
Epoch 106/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1748 - acc: 0.9377 - val_loss: 0.4233 - val_acc: 0.8870
Epoch 107/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1744 - acc: 0.9387 - val_loss: 0.5987 - val_acc: 0.8545
Epoch 108/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1754 - acc: 0.9378 - val_loss: 0.4263 - val_acc: 0.8817
Epoch 109/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1725 - acc: 0.9387 - val_loss: 0.6318 - val_acc: 0.8534
Epoch 110/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1712 - acc: 0.9386 - val_loss: 0.6007 - val_acc: 0.8501
Epoch 111/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1690 - acc: 0.9406 - val_loss: 0.4991 - val_acc: 0.8734
Epoch 112/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1685 - acc: 0.9405 - val_loss: 0.4216 - val_acc: 0.8869
Epoch 113/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1676 - acc: 0.9411 - val_loss: 0.4996 - val_acc: 0.8698
Epoch 114/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1680 - acc: 0.9405 - val_loss: 0.4247 - val_acc: 0.8848
Epoch 115/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1676 - acc: 0.9403 - val_loss: 0.4713 - val_acc: 0.8780
Epoch 116/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1697 - acc: 0.9398 - val_loss: 0.5057 - val_acc: 0.8692
Epoch 117/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1651 - acc: 0.9417 - val_loss: 0.4786 - val_acc: 0.8780
Epoch 118/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1669 - acc: 0.9413 - val_loss: 0.4522 - val_acc: 0.8724
Epoch 119/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1618 - acc: 0.9424 - val_loss: 0.5618 - val_acc: 0.8580
Epoch 120/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1660 - acc: 0.9416 - val_loss: 0.5377 - val_acc: 0.8649
Epoch 121/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1648 - acc: 0.9415 - val_loss: 0.4511 - val_acc: 0.8778
Epoch 122/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1631 - acc: 0.9417 - val_loss: 0.4817 - val_acc: 0.8743
Epoch 123/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1626 - acc: 0.9423 - val_loss: 0.5036 - val_acc: 0.8744
Epoch 124/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1602 - acc: 0.9439 - val_loss: 0.5037 - val_acc: 0.8731
Epoch 125/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1627 - acc: 0.9423 - val_loss: 0.4242 - val_acc: 0.8856
Epoch 126/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1585 - acc: 0.9440 - val_loss: 0.4616 - val_acc: 0.8767
Epoch 127/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1587 - acc: 0.9442 - val_loss: 0.4562 - val_acc: 0.8794
Epoch 128/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1563 - acc: 0.9443 - val_loss: 0.5046 - val_acc: 0.8686
Epoch 129/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1605 - acc: 0.9436 - val_loss: 0.5253 - val_acc: 0.8617
Epoch 130/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1580 - acc: 0.9432 - val_loss: 0.4450 - val_acc: 0.8883
Epoch 131/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1552 - acc: 0.9448 - val_loss: 0.4745 - val_acc: 0.8846
Epoch 132/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1563 - acc: 0.9459 - val_loss: 0.6061 - val_acc: 0.8543
Epoch 133/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1568 - acc: 0.9439 - val_loss: 0.4569 - val_acc: 0.8793
Epoch 134/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1490 - acc: 0.9471 - val_loss: 0.4498 - val_acc: 0.8844
Epoch 135/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1468 - acc: 0.9476 - val_loss: 0.4428 - val_acc: 0.8892
Epoch 136/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1507 - acc: 0.9476 - val_loss: 0.4579 - val_acc: 0.8779
Epoch 137/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1525 - acc: 0.9465 - val_loss: 0.4527 - val_acc: 0.8849
Epoch 138/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1516 - acc: 0.9456 - val_loss: 0.4746 - val_acc: 0.8796
Epoch 139/200
391/391 [==============================] - 23s 59ms/step - loss: 0.1448 - acc: 0.9488 - val_loss: 0.5592 - val_acc: 0.8707
Epoch 140/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1497 - acc: 0.9478 - val_loss: 0.4860 - val_acc: 0.8801
Epoch 141/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1466 - acc: 0.9482 - val_loss: 0.4718 - val_acc: 0.8791
Epoch 142/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1496 - acc: 0.9482 - val_loss: 0.4016 - val_acc: 0.8943
Epoch 143/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1487 - acc: 0.9465 - val_loss: 0.5368 - val_acc: 0.8675
Epoch 144/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1472 - acc: 0.9475 - val_loss: 0.4463 - val_acc: 0.8821
Epoch 145/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1432 - acc: 0.9488 - val_loss: 0.4599 - val_acc: 0.8809
Epoch 146/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1448 - acc: 0.9486 - val_loss: 0.4352 - val_acc: 0.8874
Epoch 147/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1442 - acc: 0.9485 - val_loss: 0.5291 - val_acc: 0.8719
Epoch 148/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1411 - acc: 0.9504 - val_loss: 0.5725 - val_acc: 0.8674
Epoch 149/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1458 - acc: 0.9484 - val_loss: 0.4902 - val_acc: 0.8747
Epoch 150/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1399 - acc: 0.9507 - val_loss: 0.5286 - val_acc: 0.8694
Epoch 151/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1439 - acc: 0.9492 - val_loss: 0.5606 - val_acc: 0.8616
Epoch 152/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1440 - acc: 0.9493 - val_loss: 0.5527 - val_acc: 0.8723
Epoch 153/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1393 - acc: 0.9509 - val_loss: 0.4535 - val_acc: 0.8882
Epoch 154/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1446 - acc: 0.9504 - val_loss: 0.4456 - val_acc: 0.8906
Epoch 155/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1404 - acc: 0.9497 - val_loss: 0.5670 - val_acc: 0.8694
Epoch 156/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1404 - acc: 0.9496 - val_loss: 0.6297 - val_acc: 0.8567
Epoch 157/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1365 - acc: 0.9516 - val_loss: 0.5028 - val_acc: 0.8827
Epoch 158/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1419 - acc: 0.9505 - val_loss: 0.5177 - val_acc: 0.8680
Epoch 159/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1348 - acc: 0.9527 - val_loss: 0.4192 - val_acc: 0.8911
Epoch 160/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1323 - acc: 0.9525 - val_loss: 0.5072 - val_acc: 0.8753
Epoch 161/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1333 - acc: 0.9523 - val_loss: 0.4894 - val_acc: 0.8844
Epoch 162/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1378 - acc: 0.9510 - val_loss: 0.5226 - val_acc: 0.8746
Epoch 163/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1363 - acc: 0.9519 - val_loss: 0.4527 - val_acc: 0.8861
Epoch 164/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1386 - acc: 0.9522 - val_loss: 0.4996 - val_acc: 0.8812
Epoch 165/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1333 - acc: 0.9533 - val_loss: 0.4746 - val_acc: 0.8872
Epoch 166/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1349 - acc: 0.9526 - val_loss: 0.4563 - val_acc: 0.8922
Epoch 167/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1342 - acc: 0.9529 - val_loss: 0.5547 - val_acc: 0.8726
Epoch 168/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1287 - acc: 0.9547 - val_loss: 0.5149 - val_acc: 0.8820
Epoch 169/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1327 - acc: 0.9542 - val_loss: 0.4878 - val_acc: 0.8847
Epoch 170/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1311 - acc: 0.9525 - val_loss: 0.4730 - val_acc: 0.8803
Epoch 171/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1315 - acc: 0.9545 - val_loss: 0.4229 - val_acc: 0.8901
Epoch 172/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1325 - acc: 0.9542 - val_loss: 0.4809 - val_acc: 0.8827
Epoch 173/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1331 - acc: 0.9521 - val_loss: 0.4661 - val_acc: 0.8909
Epoch 174/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1340 - acc: 0.9528 - val_loss: 0.4696 - val_acc: 0.8858
Epoch 175/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1296 - acc: 0.9546 - val_loss: 0.5730 - val_acc: 0.8742
Epoch 176/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1258 - acc: 0.9560 - val_loss: 0.4614 - val_acc: 0.8865
Epoch 177/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1311 - acc: 0.9541 - val_loss: 0.4422 - val_acc: 0.8904
Epoch 178/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1295 - acc: 0.9542 - val_loss: 0.4684 - val_acc: 0.8865
Epoch 179/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1242 - acc: 0.9562 - val_loss: 0.4612 - val_acc: 0.8912
Epoch 180/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1275 - acc: 0.9556 - val_loss: 0.5041 - val_acc: 0.8786
Epoch 181/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1283 - acc: 0.9548 - val_loss: 0.5022 - val_acc: 0.8834
Epoch 182/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1219 - acc: 0.9572 - val_loss: 0.4979 - val_acc: 0.8851
Epoch 183/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1272 - acc: 0.9555 - val_loss: 0.4815 - val_acc: 0.8854
Epoch 184/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1279 - acc: 0.9538 - val_loss: 0.6862 - val_acc: 0.8593
Epoch 185/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1262 - acc: 0.9555 - val_loss: 0.4752 - val_acc: 0.8863
Epoch 186/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1264 - acc: 0.9557 - val_loss: 0.5244 - val_acc: 0.8808
Epoch 187/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1278 - acc: 0.9549 - val_loss: 0.4805 - val_acc: 0.8854
Epoch 188/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1223 - acc: 0.9568 - val_loss: 0.4853 - val_acc: 0.8874
Epoch 189/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1243 - acc: 0.9562 - val_loss: 0.5000 - val_acc: 0.8816
Epoch 190/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1217 - acc: 0.9565 - val_loss: 0.4704 - val_acc: 0.8856
Epoch 191/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1208 - acc: 0.9573 - val_loss: 0.4711 - val_acc: 0.8868
Epoch 192/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1239 - acc: 0.9563 - val_loss: 0.5143 - val_acc: 0.8818
Epoch 193/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1269 - acc: 0.9551 - val_loss: 0.4407 - val_acc: 0.8894
Epoch 194/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1234 - acc: 0.9570 - val_loss: 0.5062 - val_acc: 0.8812
Epoch 195/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1217 - acc: 0.9565 - val_loss: 0.4335 - val_acc: 0.8935
Epoch 196/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1194 - acc: 0.9576 - val_loss: 0.5052 - val_acc: 0.8837
Epoch 197/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1173 - acc: 0.9572 - val_loss: 0.4437 - val_acc: 0.8948
Epoch 198/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1173 - acc: 0.9586 - val_loss: 0.5094 - val_acc: 0.8829
Epoch 199/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1216 - acc: 0.9568 - val_loss: 0.5125 - val_acc: 0.8873
Epoch 200/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1199 - acc: 0.9574 - val_loss: 0.4861 - val_acc: 0.8892