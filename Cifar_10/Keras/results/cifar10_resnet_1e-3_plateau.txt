# Training parameters
LEARNING_RATE = 1e-3
DATA_AUGMENTATION = True 
REGULARIZATION = 0.0
BATCH_SIZE = 128
EPOCHS = 200
es = keras.callbacks.EarlyStopping(monitor='val_acc', patience=15)
reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=10, verbose=1)


Using TensorFlow backend.
Using data augmentation.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 32, 32, 16)   448         input_1[0][0]
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 32, 32, 16)   64          conv1[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           conv1_bn[0][0]
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_1[0][0]
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2a_branch2a[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           bn2a_branch2a[0][0]
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_2[0][0]
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2a_branch2b[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           bn2a_branch2b[0][0]
                                                                 activation_1[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_3[0][0]
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2b_branch2a[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           bn2b_branch2a[0][0]
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_4[0][0]
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2b_branch2b[0][0]
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           bn2b_branch2b[0][0]
                                                                 activation_3[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]
__________________________________________________________________________________________________
res2c_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_5[0][0]
__________________________________________________________________________________________________
bn2c_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2c_branch2a[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           bn2c_branch2a[0][0]
__________________________________________________________________________________________________
res2c_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_6[0][0]
__________________________________________________________________________________________________
bn2c_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2c_branch2b[0][0]
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           bn2c_branch2b[0][0]
                                                                 activation_5[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 16, 16, 32)   4640        activation_7[0][0]
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3a_branch2a[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           bn3a_branch2a[0][0]
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_8[0][0]
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 16, 16, 32)   544         activation_7[0][0]
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3a_branch2b[0][0]
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 16, 16, 32)   128         res3a_branch1[0][0]
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           bn3a_branch2b[0][0]
                                                                 bn3a_branch1[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 16, 16, 32)   9248        activation_9[0][0]
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3b_branch2a[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           bn3b_branch2a[0][0]
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_10[0][0]
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3b_branch2b[0][0]
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           bn3b_branch2b[0][0]
                                                                 activation_9[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]
__________________________________________________________________________________________________
res3c_branch2a (Conv2D)         (None, 16, 16, 32)   9248        activation_11[0][0]
__________________________________________________________________________________________________
bn3c_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3c_branch2a[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           bn3c_branch2a[0][0]
__________________________________________________________________________________________________
res3c_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_12[0][0]
__________________________________________________________________________________________________
bn3c_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3c_branch2b[0][0]
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           bn3c_branch2b[0][0]
                                                                 activation_11[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 8, 8, 64)     18496       activation_13[0][0]
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4a_branch2a[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           bn4a_branch2a[0][0]
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_14[0][0]
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 8, 8, 64)     2112        activation_13[0][0]
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4a_branch2b[0][0]
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 8, 8, 64)     256         res4a_branch1[0][0]
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           bn4a_branch2b[0][0]
                                                                 bn4a_branch1[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 8, 8, 64)     36928       activation_15[0][0]
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4b_branch2a[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           bn4b_branch2a[0][0]
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_16[0][0]
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4b_branch2b[0][0]
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           bn4b_branch2b[0][0]
                                                                 activation_15[0][0]
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]
__________________________________________________________________________________________________
res4c_branch2a (Conv2D)         (None, 8, 8, 64)     36928       activation_17[0][0]
__________________________________________________________________________________________________
bn4c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4c_branch2a[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           bn4c_branch2a[0][0]
__________________________________________________________________________________________________
res4c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_18[0][0]
__________________________________________________________________________________________________
bn4c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4c_branch2b[0][0]
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           bn4c_branch2b[0][0]
                                                                 activation_17[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]
__________________________________________________________________________________________________
avg_pool (AveragePooling2D)     (None, 4, 4, 64)     0           activation_19[0][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1024)         0           avg_pool[0][0]
__________________________________________________________________________________________________
fc (Dense)                      (None, 10)           10250       flatten_1[0][0]
==================================================================================================
Total params: 284,426
Trainable params: 282,858
Non-trainable params: 1,568
__________________________________________________________________________________________________
Epoch 1/200
391/391 [==============================] - 26s 66ms/step - loss: 1.7592 - acc: 0.3650 - val_loss: 1.5308 - val_acc: 0.4517
Epoch 2/200
391/391 [==============================] - 22s 56ms/step - loss: 1.4350 - acc: 0.4769 - val_loss: 1.3560 - val_acc: 0.5296
Epoch 3/200
391/391 [==============================] - 22s 56ms/step - loss: 1.2502 - acc: 0.5502 - val_loss: 1.1331 - val_acc: 0.6094
Epoch 4/200
391/391 [==============================] - 22s 57ms/step - loss: 1.1147 - acc: 0.6055 - val_loss: 1.6929 - val_acc: 0.5098
Epoch 5/200
391/391 [==============================] - 22s 56ms/step - loss: 1.0090 - acc: 0.6422 - val_loss: 1.0682 - val_acc: 0.6339
Epoch 6/200
391/391 [==============================] - 22s 56ms/step - loss: 0.9224 - acc: 0.6727 - val_loss: 1.1932 - val_acc: 0.6390
Epoch 7/200
391/391 [==============================] - 22s 56ms/step - loss: 0.8663 - acc: 0.6951 - val_loss: 1.0921 - val_acc: 0.6545
Epoch 8/200
391/391 [==============================] - 22s 56ms/step - loss: 0.8086 - acc: 0.7152 - val_loss: 1.0524 - val_acc: 0.6668
Epoch 9/200
391/391 [==============================] - 22s 56ms/step - loss: 0.7633 - acc: 0.7303 - val_loss: 1.0765 - val_acc: 0.6690
Epoch 10/200
391/391 [==============================] - 22s 56ms/step - loss: 0.7269 - acc: 0.7459 - val_loss: 1.2906 - val_acc: 0.6592
Epoch 11/200
391/391 [==============================] - 22s 56ms/step - loss: 0.6955 - acc: 0.7565 - val_loss: 0.7834 - val_acc: 0.7424
Epoch 12/200
391/391 [==============================] - 22s 56ms/step - loss: 0.6639 - acc: 0.7704 - val_loss: 1.2131 - val_acc: 0.6592
Epoch 13/200
391/391 [==============================] - 22s 57ms/step - loss: 0.6395 - acc: 0.7750 - val_loss: 0.7641 - val_acc: 0.7472
Epoch 14/200
391/391 [==============================] - 22s 56ms/step - loss: 0.6099 - acc: 0.7887 - val_loss: 0.8116 - val_acc: 0.7447
Epoch 15/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5899 - acc: 0.7952 - val_loss: 0.6087 - val_acc: 0.7967
Epoch 16/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5724 - acc: 0.8006 - val_loss: 1.1573 - val_acc: 0.6829
Epoch 17/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5544 - acc: 0.8062 - val_loss: 0.6723 - val_acc: 0.7842
Epoch 18/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5437 - acc: 0.8117 - val_loss: 0.6418 - val_acc: 0.7876
Epoch 19/200
391/391 [==============================] - 22s 57ms/step - loss: 0.5218 - acc: 0.8173 - val_loss: 0.7791 - val_acc: 0.7673
Epoch 20/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5065 - acc: 0.8234 - val_loss: 0.6497 - val_acc: 0.7937
Epoch 21/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4986 - acc: 0.8249 - val_loss: 0.7620 - val_acc: 0.7646
Epoch 22/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4818 - acc: 0.8320 - val_loss: 0.7640 - val_acc: 0.7702
Epoch 23/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4734 - acc: 0.8356 - val_loss: 0.5601 - val_acc: 0.8137
Epoch 24/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4622 - acc: 0.8387 - val_loss: 0.5755 - val_acc: 0.8153
Epoch 25/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4642 - acc: 0.8376 - val_loss: 0.7733 - val_acc: 0.7569
Epoch 26/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4394 - acc: 0.8458 - val_loss: 0.5501 - val_acc: 0.8232
Epoch 27/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4291 - acc: 0.8509 - val_loss: 0.5786 - val_acc: 0.8128
Epoch 28/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4288 - acc: 0.8492 - val_loss: 1.1724 - val_acc: 0.7118
Epoch 29/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4231 - acc: 0.8524 - val_loss: 0.5252 - val_acc: 0.8318
Epoch 30/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4087 - acc: 0.8585 - val_loss: 0.5596 - val_acc: 0.8225
Epoch 31/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4029 - acc: 0.8579 - val_loss: 0.7404 - val_acc: 0.7766
Epoch 32/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3900 - acc: 0.8630 - val_loss: 0.6104 - val_acc: 0.8047
Epoch 33/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3877 - acc: 0.8634 - val_loss: 0.5073 - val_acc: 0.8297
Epoch 34/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3811 - acc: 0.8655 - val_loss: 0.5672 - val_acc: 0.8227
Epoch 35/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3744 - acc: 0.8680 - val_loss: 0.5713 - val_acc: 0.8182
Epoch 36/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3698 - acc: 0.8725 - val_loss: 0.5950 - val_acc: 0.8141
Epoch 37/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3620 - acc: 0.8740 - val_loss: 0.6196 - val_acc: 0.8056
Epoch 38/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3600 - acc: 0.8734 - val_loss: 0.6931 - val_acc: 0.7941
Epoch 39/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3555 - acc: 0.8767 - val_loss: 0.5674 - val_acc: 0.8252

Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 40/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2966 - acc: 0.8977 - val_loss: 0.4068 - val_acc: 0.8724
Epoch 41/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2793 - acc: 0.9015 - val_loss: 0.4111 - val_acc: 0.8706
Epoch 42/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2727 - acc: 0.9040 - val_loss: 0.4287 - val_acc: 0.8650
Epoch 43/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2719 - acc: 0.9060 - val_loss: 0.4124 - val_acc: 0.8699
Epoch 44/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2668 - acc: 0.9067 - val_loss: 0.4008 - val_acc: 0.8733
Epoch 45/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2645 - acc: 0.9076 - val_loss: 0.4224 - val_acc: 0.8701
Epoch 46/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2624 - acc: 0.9080 - val_loss: 0.4144 - val_acc: 0.8712
Epoch 47/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2623 - acc: 0.9088 - val_loss: 0.4192 - val_acc: 0.8698
Epoch 48/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2573 - acc: 0.9096 - val_loss: 0.4201 - val_acc: 0.8689
Epoch 49/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2566 - acc: 0.9093 - val_loss: 0.4289 - val_acc: 0.8671
Epoch 50/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2533 - acc: 0.9108 - val_loss: 0.4168 - val_acc: 0.8712
Epoch 51/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2538 - acc: 0.9111 - val_loss: 0.4154 - val_acc: 0.8722
Epoch 52/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2531 - acc: 0.9120 - val_loss: 0.4292 - val_acc: 0.8676
Epoch 53/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2517 - acc: 0.9117 - val_loss: 0.3935 - val_acc: 0.8792
Epoch 54/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2469 - acc: 0.9128 - val_loss: 0.4509 - val_acc: 0.8682
Epoch 55/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2465 - acc: 0.9136 - val_loss: 0.4252 - val_acc: 0.8710
Epoch 56/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2469 - acc: 0.9136 - val_loss: 0.4102 - val_acc: 0.8758
Epoch 57/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2437 - acc: 0.9143 - val_loss: 0.4402 - val_acc: 0.8661
Epoch 58/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2428 - acc: 0.9143 - val_loss: 0.4250 - val_acc: 0.8705
Epoch 59/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2370 - acc: 0.9167 - val_loss: 0.4110 - val_acc: 0.8750
Epoch 60/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2449 - acc: 0.9146 - val_loss: 0.4312 - val_acc: 0.8698
Epoch 61/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2366 - acc: 0.9173 - val_loss: 0.4273 - val_acc: 0.8709
Epoch 62/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2375 - acc: 0.9162 - val_loss: 0.4281 - val_acc: 0.8693
Epoch 63/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2344 - acc: 0.9166 - val_loss: 0.4196 - val_acc: 0.8689

Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 64/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2300 - acc: 0.9196 - val_loss: 0.4140 - val_acc: 0.8737
Epoch 65/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2315 - acc: 0.9188 - val_loss: 0.4081 - val_acc: 0.8757
Epoch 66/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2318 - acc: 0.9196 - val_loss: 0.4133 - val_acc: 0.8741
Epoch 67/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2298 - acc: 0.9191 - val_loss: 0.4071 - val_acc: 0.8750
Epoch 68/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2293 - acc: 0.9189 - val_loss: 0.4099 - val_acc: 0.8750