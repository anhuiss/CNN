# Training parameters
LEARNING_RATE = 3e-3
DATA_AUGMENTATION = True
REGULARIZATION = 0.0
BATCH_SIZE = 128
EPOCHS = 200
es = keras.callbacks.EarlyStopping(monitor='val_acc', patience=15)
reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=10, verbose=1)


Using TensorFlow backend.
Using data augmentation.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 32, 32, 16)   448         input_1[0][0]
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 32, 32, 16)   64          conv1[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           conv1_bn[0][0]
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_1[0][0]
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2a_branch2a[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           bn2a_branch2a[0][0]
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_2[0][0]
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2a_branch2b[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           bn2a_branch2b[0][0]
                                                                 activation_1[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_3[0][0]
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2b_branch2a[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           bn2b_branch2a[0][0]
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_4[0][0]
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2b_branch2b[0][0]
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           bn2b_branch2b[0][0]
                                                                 activation_3[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]
__________________________________________________________________________________________________
res2c_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_5[0][0]
__________________________________________________________________________________________________
bn2c_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res2c_branch2a[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           bn2c_branch2a[0][0]
__________________________________________________________________________________________________
res2c_branch2b (Conv2D)         (None, 32, 32, 16)   2320        activation_6[0][0]
__________________________________________________________________________________________________
bn2c_branch2b (BatchNormalizati (None, 32, 32, 16)   64          res2c_branch2b[0][0]
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           bn2c_branch2b[0][0]
                                                                 activation_5[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 16, 16, 32)   4640        activation_7[0][0]
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3a_branch2a[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           bn3a_branch2a[0][0]
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_8[0][0]
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 16, 16, 32)   544         activation_7[0][0]
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3a_branch2b[0][0]
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 16, 16, 32)   128         res3a_branch1[0][0]
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           bn3a_branch2b[0][0]
                                                                 bn3a_branch1[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 16, 16, 32)   9248        activation_9[0][0]
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3b_branch2a[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           bn3b_branch2a[0][0]
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_10[0][0]
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3b_branch2b[0][0]
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           bn3b_branch2b[0][0]
                                                                 activation_9[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]
__________________________________________________________________________________________________
res3c_branch2a (Conv2D)         (None, 16, 16, 32)   9248        activation_11[0][0]
__________________________________________________________________________________________________
bn3c_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res3c_branch2a[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           bn3c_branch2a[0][0]
__________________________________________________________________________________________________
res3c_branch2b (Conv2D)         (None, 16, 16, 32)   9248        activation_12[0][0]
__________________________________________________________________________________________________
bn3c_branch2b (BatchNormalizati (None, 16, 16, 32)   128         res3c_branch2b[0][0]
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           bn3c_branch2b[0][0]
                                                                 activation_11[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 8, 8, 64)     18496       activation_13[0][0]
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4a_branch2a[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           bn4a_branch2a[0][0]
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_14[0][0]
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 8, 8, 64)     2112        activation_13[0][0]
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4a_branch2b[0][0]
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 8, 8, 64)     256         res4a_branch1[0][0]
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           bn4a_branch2b[0][0]
                                                                 bn4a_branch1[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 8, 8, 64)     36928       activation_15[0][0]
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4b_branch2a[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           bn4b_branch2a[0][0]
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_16[0][0]
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4b_branch2b[0][0]
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           bn4b_branch2b[0][0]
                                                                 activation_15[0][0]
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]
__________________________________________________________________________________________________
res4c_branch2a (Conv2D)         (None, 8, 8, 64)     36928       activation_17[0][0]
__________________________________________________________________________________________________
bn4c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res4c_branch2a[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           bn4c_branch2a[0][0]
__________________________________________________________________________________________________
res4c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_18[0][0]
__________________________________________________________________________________________________
bn4c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res4c_branch2b[0][0]
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           bn4c_branch2b[0][0]
                                                                 activation_17[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]
__________________________________________________________________________________________________
avg_pool (AveragePooling2D)     (None, 4, 4, 64)     0           activation_19[0][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1024)         0           avg_pool[0][0]
__________________________________________________________________________________________________
fc (Dense)                      (None, 10)           10250       flatten_1[0][0]
==================================================================================================
Total params: 284,426
Trainable params: 282,858
Non-trainable params: 1,568
__________________________________________________________________________________________________
Epoch 1/200
391/391 [==============================] - 29s 73ms/step - loss: 1.7555 - acc: 0.3820 - val_loss: 1.4860 - val_acc: 0.4715
Epoch 2/200
391/391 [==============================] - 22s 57ms/step - loss: 1.3705 - acc: 0.5093 - val_loss: 2.0680 - val_acc: 0.4339
Epoch 3/200
391/391 [==============================] - 22s 57ms/step - loss: 1.1672 - acc: 0.5856 - val_loss: 1.7019 - val_acc: 0.4866
Epoch 4/200
391/391 [==============================] - 22s 56ms/step - loss: 1.0037 - acc: 0.6460 - val_loss: 1.1330 - val_acc: 0.6393
Epoch 5/200
391/391 [==============================] - 22s 56ms/step - loss: 0.8891 - acc: 0.6881 - val_loss: 1.0025 - val_acc: 0.6661
Epoch 6/200
391/391 [==============================] - 22s 56ms/step - loss: 0.8096 - acc: 0.7167 - val_loss: 1.3064 - val_acc: 0.6086
Epoch 7/200
391/391 [==============================] - 22s 57ms/step - loss: 0.7445 - acc: 0.7402 - val_loss: 1.4014 - val_acc: 0.6080
Epoch 8/200
391/391 [==============================] - 22s 57ms/step - loss: 0.6925 - acc: 0.7577 - val_loss: 1.2697 - val_acc: 0.6225
Epoch 9/200
391/391 [==============================] - 22s 57ms/step - loss: 0.6499 - acc: 0.7736 - val_loss: 0.9481 - val_acc: 0.6997
Epoch 10/200
391/391 [==============================] - 22s 56ms/step - loss: 0.6146 - acc: 0.7869 - val_loss: 0.7748 - val_acc: 0.7499
Epoch 11/200
391/391 [==============================] - 22s 57ms/step - loss: 0.5905 - acc: 0.7965 - val_loss: 0.8165 - val_acc: 0.7418
Epoch 12/200
391/391 [==============================] - 22s 57ms/step - loss: 0.5641 - acc: 0.8036 - val_loss: 0.6293 - val_acc: 0.7915
Epoch 13/200
391/391 [==============================] - 22s 56ms/step - loss: 0.5365 - acc: 0.8139 - val_loss: 0.7746 - val_acc: 0.7608
Epoch 14/200
391/391 [==============================] - 22s 57ms/step - loss: 0.5176 - acc: 0.8200 - val_loss: 0.7498 - val_acc: 0.7652
Epoch 15/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4977 - acc: 0.8288 - val_loss: 0.7857 - val_acc: 0.7590
Epoch 16/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4891 - acc: 0.8310 - val_loss: 0.8525 - val_acc: 0.7459
Epoch 17/200
391/391 [==============================] - 22s 56ms/step - loss: 0.4783 - acc: 0.8339 - val_loss: 0.6338 - val_acc: 0.7951
Epoch 18/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4557 - acc: 0.8417 - val_loss: 0.6931 - val_acc: 0.7814
Epoch 19/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4444 - acc: 0.8462 - val_loss: 0.5343 - val_acc: 0.8216
Epoch 20/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4303 - acc: 0.8491 - val_loss: 0.5758 - val_acc: 0.8115
Epoch 21/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4257 - acc: 0.8523 - val_loss: 0.5670 - val_acc: 0.8182
Epoch 22/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4091 - acc: 0.8571 - val_loss: 0.6308 - val_acc: 0.8038
Epoch 23/200
391/391 [==============================] - 22s 57ms/step - loss: 0.4063 - acc: 0.8604 - val_loss: 0.7095 - val_acc: 0.7891
Epoch 24/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3934 - acc: 0.8630 - val_loss: 0.7979 - val_acc: 0.7628
Epoch 25/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3849 - acc: 0.8662 - val_loss: 0.7418 - val_acc: 0.7847
Epoch 26/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3780 - acc: 0.8665 - val_loss: 0.5167 - val_acc: 0.8384
Epoch 27/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3686 - acc: 0.8707 - val_loss: 0.7060 - val_acc: 0.7972
Epoch 28/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3623 - acc: 0.8731 - val_loss: 0.4983 - val_acc: 0.8441
Epoch 29/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3543 - acc: 0.8762 - val_loss: 0.6627 - val_acc: 0.8053
Epoch 30/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3485 - acc: 0.8787 - val_loss: 0.4992 - val_acc: 0.8452
Epoch 31/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3406 - acc: 0.8822 - val_loss: 0.4611 - val_acc: 0.8549
Epoch 32/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3361 - acc: 0.8825 - val_loss: 0.5016 - val_acc: 0.8410
Epoch 33/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3322 - acc: 0.8862 - val_loss: 0.5801 - val_acc: 0.8155
Epoch 34/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3253 - acc: 0.8861 - val_loss: 0.6492 - val_acc: 0.8175
Epoch 35/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3211 - acc: 0.8893 - val_loss: 0.5824 - val_acc: 0.8351
Epoch 36/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3222 - acc: 0.8886 - val_loss: 0.4750 - val_acc: 0.8528
Epoch 37/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3121 - acc: 0.8911 - val_loss: 0.6054 - val_acc: 0.8267
Epoch 38/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3107 - acc: 0.8921 - val_loss: 0.6584 - val_acc: 0.8174
Epoch 39/200
391/391 [==============================] - 22s 56ms/step - loss: 0.3082 - acc: 0.8932 - val_loss: 0.6893 - val_acc: 0.8133
Epoch 40/200
391/391 [==============================] - 22s 57ms/step - loss: 0.3007 - acc: 0.8959 - val_loss: 0.4594 - val_acc: 0.8616
Epoch 41/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2961 - acc: 0.8955 - val_loss: 0.6054 - val_acc: 0.8323
Epoch 42/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2908 - acc: 0.8990 - val_loss: 0.7726 - val_acc: 0.8084
Epoch 43/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2869 - acc: 0.8987 - val_loss: 0.5038 - val_acc: 0.8483
Epoch 44/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2827 - acc: 0.9015 - val_loss: 0.6640 - val_acc: 0.8209
Epoch 45/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2735 - acc: 0.9042 - val_loss: 0.4971 - val_acc: 0.8497
Epoch 46/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2767 - acc: 0.9039 - val_loss: 0.6115 - val_acc: 0.8335
Epoch 47/200
391/391 [==============================] - 22s 57ms/step - loss: 0.2711 - acc: 0.9047 - val_loss: 0.6188 - val_acc: 0.8227
Epoch 48/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2698 - acc: 0.9051 - val_loss: 0.4681 - val_acc: 0.8554
Epoch 49/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2651 - acc: 0.9067 - val_loss: 0.6149 - val_acc: 0.8241
Epoch 50/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2633 - acc: 0.9085 - val_loss: 0.5579 - val_acc: 0.8444

Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00030000000260770325.
Epoch 51/200
391/391 [==============================] - 22s 56ms/step - loss: 0.2170 - acc: 0.9240 - val_loss: 0.3746 - val_acc: 0.8871
Epoch 52/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1945 - acc: 0.9315 - val_loss: 0.3930 - val_acc: 0.8865
Epoch 53/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1901 - acc: 0.9335 - val_loss: 0.4140 - val_acc: 0.8834
Epoch 54/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1848 - acc: 0.9345 - val_loss: 0.3659 - val_acc: 0.8920
Epoch 55/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1820 - acc: 0.9358 - val_loss: 0.3818 - val_acc: 0.8907
Epoch 56/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1814 - acc: 0.9363 - val_loss: 0.3780 - val_acc: 0.8905
Epoch 57/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1773 - acc: 0.9370 - val_loss: 0.3862 - val_acc: 0.8889
Epoch 58/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1782 - acc: 0.9374 - val_loss: 0.3849 - val_acc: 0.8907
Epoch 59/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1717 - acc: 0.9396 - val_loss: 0.3634 - val_acc: 0.8952
Epoch 60/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1663 - acc: 0.9411 - val_loss: 0.3729 - val_acc: 0.8917
Epoch 61/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1714 - acc: 0.9400 - val_loss: 0.3881 - val_acc: 0.8917
Epoch 62/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1666 - acc: 0.9416 - val_loss: 0.4035 - val_acc: 0.8892
Epoch 63/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1695 - acc: 0.9407 - val_loss: 0.3756 - val_acc: 0.8936
Epoch 64/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1637 - acc: 0.9425 - val_loss: 0.3931 - val_acc: 0.8910
Epoch 65/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1639 - acc: 0.9418 - val_loss: 0.3907 - val_acc: 0.8920
Epoch 66/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1626 - acc: 0.9425 - val_loss: 0.3881 - val_acc: 0.8914
Epoch 67/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1609 - acc: 0.9440 - val_loss: 0.3910 - val_acc: 0.8911
Epoch 68/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1630 - acc: 0.9425 - val_loss: 0.3839 - val_acc: 0.8927
Epoch 69/200
391/391 [==============================] - 22s 57ms/step - loss: 0.1586 - acc: 0.9445 - val_loss: 0.3924 - val_acc: 0.8911

Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.
Epoch 70/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1554 - acc: 0.9451 - val_loss: 0.3845 - val_acc: 0.8931
Epoch 71/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1533 - acc: 0.9451 - val_loss: 0.3866 - val_acc: 0.8926
Epoch 72/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1502 - acc: 0.9477 - val_loss: 0.3827 - val_acc: 0.8937
Epoch 73/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1522 - acc: 0.9473 - val_loss: 0.3847 - val_acc: 0.8931
Epoch 74/200
391/391 [==============================] - 22s 56ms/step - loss: 0.1503 - acc: 0.9471 - val_loss: 0.3779 - val_acc: 0.8942